-> Loading weights from ./tmp/lidut-depth_1024x320
-> Computing predictions with size 1024x320
-> Evaluating
   Mono evaluation - using median scaling

   abs_rel |   sq_rel |     rmse | rmse_log |       a1 |       a2 |       a3 | 
&   0.145  &   1.056  &   5.145  &   0.205  &   0.819  &   0.950  &   0.983  \\  weights_0
&   0.126  &   0.813  &   5.014  &   0.203  &   0.837  &   0.950  &   0.982  \\  weights_1
&   0.120  &   0.750  &   4.826  &   0.192  &   0.852  &   0.958  &   0.985  \\  weights_2
&   0.112  &   0.742  &   4.511  &   0.183  &   0.876  &   0.962  &   0.985  \\  weights_3
&   0.111  &   0.727  &   4.465  &   0.181  &   0.876  &   0.963  &   0.985  \\  weights_4
&   0.108  &   0.686  &   4.472  &   0.181  &   0.879  &   0.964  &   0.985  \\  weights_5
&   0.113  &   0.794  &   4.552  &   0.181  &   0.879  &   0.963  &   0.984  \\  weights_6
&   0.107  &   0.729  &   4.414  &   0.178  &   0.888  &   0.965  &   0.984  \\  weights_7
&   0.105  &   0.693  &   4.455  &   0.177  &   0.883  &   0.965  &   0.985  \\  weights_8
&   0.106  &   0.730  &   4.435  &   0.177  &   0.887  &   0.965  &   0.985  \\  weights_9
&   0.111  &   0.867  &   4.718  &   0.181  &   0.884  &   0.963  &   0.984  \\  weights_10
&   0.103  &   0.698  &   4.375  &   0.176  &   0.890  &   0.965  &   0.985  \\  weights_11
&   0.103  &   0.697  &   4.404  &   0.177  &   0.890  &   0.965  &   0.984  \\  weights_12
&   0.105  &   0.708  &   4.396  &   0.178  &   0.889  &   0.965  &   0.985  \\  weights_13
&   0.105  &   0.714  &   4.373  &   0.176  &   0.891  &   0.966  &   0.985  \\  weights_14
&   0.103  &   0.730  &   4.407  &   0.176  &   0.893  &   0.965  &   0.985  \\  weights_15
&   0.102  &   0.704  &   4.354  &   0.175  &   0.892  &   0.965  &   0.985  \\  weights_16
&   0.104  &   0.720  &   4.393  &   0.177  &   0.893  &   0.965  &   0.984  \\  weights_17
&   0.102  &   0.715  &   4.373  &   0.176  &   0.893  &   0.966  &   0.984  \\  weights_18
&   0.102  &   0.730  &   4.382  &   0.175  &   0.894  &   0.966  &   0.984  \\  weights_19
&   0.103  &   0.724  &   4.376  &   0.177  &   0.894  &   0.965  &   0.984  \\  weights_20
&   0.104  &   0.733  &   4.396  &   0.177  &   0.893  &   0.965  &   0.984  \\  weights_21
&   0.103  &   0.729  &   4.378  &   0.176  &   0.894  &   0.966  &   0.984  \\  weights_22
&   0.103  &   0.748  &   4.419  &   0.176  &   0.894  &   0.965  &   0.984  \\  weights_23
&   0.102  &   0.719  &   4.373  &   0.175  &   0.895  &   0.966  &   0.984  \\  weights_24
&   0.101  &   0.703  &   4.354  &   0.175  &   0.895  &   0.966  &   0.985  \\  weights_25
&   0.102  &   0.724  &   4.382  &   0.176  &   0.894  &   0.966  &   0.984  \\  weights_26
&   0.102  &   0.734  &   4.389  &   0.176  &   0.895  &   0.966  &   0.984  \\  weights_27
&   0.102  &   0.735  &   4.393  &   0.176  &   0.894  &   0.965  &   0.984  \\  weights_28
&   0.103  &   0.733  &   4.396  &   0.176  &   0.894  &   0.965  &   0.984  \\  weights_29
&   0.106  &   0.779  &   4.480  &   0.177  &   0.891  &   0.965  &   0.984  \\  weights_30
&   0.103  &   0.723  &   4.398  &   0.176  &   0.893  &   0.965  &   0.984  \\  weights_31
&   0.105  &   0.765  &   4.438  &   0.177  &   0.893  &   0.965  &   0.984  \\  weights_32
&   0.109  &   0.801  &   4.546  &   0.183  &   0.889  &   0.964  &   0.983  \\  weights_33
&   0.105  &   0.801  &   4.462  &   0.178  &   0.892  &   0.965  &   0.984  \\  weights_34


  flops: 13.418G, params: 3.069M, flops_e: 11.503G, params_e:2.842M, flops_d:1.915G, params_d:226.627K


-> Done!
